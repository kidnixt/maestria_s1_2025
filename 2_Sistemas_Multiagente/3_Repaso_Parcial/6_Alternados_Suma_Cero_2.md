# 游닄 Gu칤a de Estudio Detallada: Minimax, Poda 풤- y Funciones de Evaluaci칩n 游

---

### **Diapositiva 1: Portada**

* **Resumen Estricto:**
    * **Curso:** Sistemas Multiagente.
    * **Tema:** Juegos Alternados: Minimax - Poda - Funciones de evaluaci칩n.
    * **Autor:** Sergio Yovine, Universidad ORT Uruguay.
    * **Fecha:** 30 de abril de 2025.

---

### **Diapositiva 2: El Problema de Minimax: La Complejidad**

* **Resumen Estricto:**
    * El algoritmo Minimax requiere recorrer el 치rbol de juego completo.
    * Su complejidad temporal es exponencial: $O(b^d)$, donde `b` es el factor de ramificaci칩n (n칰mero de jugadas posibles en promedio) y `d` es la profundidad de la b칰squeda (cu치ntos turnos hacia adelante se mira).
    * Para juegos complejos como el Ajedrez o el Go, esta complejidad hace que sea imposible explorar el 치rbol completo.
    * Esto motiva la necesidad de usar t칠cnicas para acelerar la b칰squeda, como la **Poda** y las **Funciones de Evaluaci칩n**.

* **Ecuaciones de la Diapositiva:**
    * Complejidad en tiempo: $O(b^{d})$
    * Par치metros para Ajedrez: $b \sim 35, d \sim 50$
    * Par치metros para Go: $b \sim 361, d \sim 100$

* **Ejemplo Did치ctico:**
    * Imagina un juego simple donde en cada turno hay 10 jugadas posibles (`b=10`). Si quieres planificar solo 4 turnos hacia adelante (`d=4`), necesitas evaluar $10^4 = 10,000$ posibles desenlaces. Si quieres mirar 8 turnos, el n칰mero escala a $10^8 = 100,000,000$. Para el ajedrez, con $b \approx 35$, es computacionalmente inviable.

* **Flashcards 游:**
    * **Pregunta:** 쮺u치l es la complejidad temporal del algoritmo Minimax y qu칠 significan sus par치metros `b` y `d`?
        > **Respuesta:** La complejidad es $O(b^d)$, donde `b` es el factor de ramificaci칩n (movimientos promedio por turno) y `d` es la profundidad de la b칰squeda (turnos a futuro).
    * **Pregunta:** 쯈u칠 dos t칠cnicas se proponen para mitigar la complejidad de Minimax?
        > **Respuesta:** 1. La Poda (para evitar explorar ramas in칰tiles). 2. Las Funciones de Evaluaci칩n (para no tener que explorar hasta el final del juego).

---

### **Diapositiva 3: Introducci칩n a la Poda 풤-**

* **Resumen Estricto:**
    * La **Poda Alfa-Beta** ($\alpha-\beta$) es un algoritmo de optimizaci칩n para Minimax que pertenece a la familia de algoritmos "branch-and-bound".
    * La idea es dejar de explorar una rama del 치rbol de juego tan pronto como se demuestra que no puede influir en la decisi칩n final.
    * En el ejemplo, despu칠s de analizar la rama A, el jugador MAX sabe que puede obtener un valor de **al menos 3**. Al empezar a analizar la rama B, el jugador MIN puede forzar un valor de **como m치ximo 2**. Como MAX nunca elegir치 una rama que le da $\le 2$ si ya tiene una que le da $\ge 3$, no es necesario seguir explorando la rama B. Se puede "podar".

* **Ecuaciones de la Diapositiva:**
    * C치lculo del valor en la ra칤z (sin poda): $R=max\{A,B\}=max\{min\{3,5\},min\{2,10\}\}$
    * Inferencia tras evaluar A: $R \ge 3$
    * Inferencia tras evaluar el primer hijo de B: $B \le 2$
    * Decisi칩n final de R: $R=max\{\ge3,\le2\}=\ge3$

* **Flashcards 游:**
    * **Pregunta:** 쮺u치l es la idea fundamental de la poda Alfa-Beta?
        > **Respuesta:** Es ignorar (podar) partes del 치rbol de b칰squeda que no pueden mejorar el resultado de la decisi칩n que ya se ha encontrado.

---

### **Diapositiva 4: Valores Alfa (풤) y Beta ()**

* **Resumen Estricto:**
    * Se definen los valores $\alpha$ y $\beta$ que dan nombre al algoritmo.
    * **$\alpha$ (alpha):** Es el mejor valor (el m치s alto) que el jugador **MAX** puede garantizarse hasta el momento en el camino actual. Es una cota inferior.
    * **$\beta$ (beta):** Es el mejor valor (el m치s bajo) que el jugador **MIN** puede garantizarse hasta el momento en el camino actual. Es una cota superior.

* **Ecuaciones de la Diapositiva (Notaci칩n):**
    * La diapositiva usa $a_s$ para $\alpha$ y $b_s$ para $\beta$.
    * $a_s$: cota inferior en un nodo MAX. Ejemplo: $a_R = 3$.
    * $b_s$: cota superior en un nodo MIN. Ejemplo: $b_A = 3$, $b_B = 2$.

* **Ejemplo Did치ctico:**
    * **Valor $\alpha$ (MAX):** Imagina que est치s jugando ajedrez y encuentras una secuencia de jugadas que te garantiza ganar al menos un pe칩n (un valor de +1). Fijas tu $\alpha = 1$. A partir de ahora, solo te interesar치n las jugadas que te den un resultado > 1.
    * **Valor $\beta$ (MIN):** Ahora es el turno de tu oponente. 칄l encuentra una jugada que le garantiza que t칰 no ganar치s m치s de una torre (+5). Fija su $\beta = 5$.
    * La b칰squeda contin칰a manteniendo estos valores.

---

### **Diapositiva 5: Condici칩n de Poda 풤-**

* **Resumen Estricto:**
    * Se generaliza la condici칩n de poda. Se mantienen los valores $\alpha$ (el m치ximo de los valores de nodos MAX ancestros) y $\beta$ (el m칤nimo de los valores de nodos MIN ancestros).
    * Se puede podar una rama cuando $\alpha \ge \beta$. Esto significa que el mejor resultado que MAX puede forzar ($\alpha$) ya es mayor o igual al peor resultado que MIN puede forzar ($\beta$) en la rama actual, por lo que MAX nunca elegir치 esta rama.
    * Se asegura que el algoritmo sigue calculando el valor minimax correcto.

* **Ecuaciones de la Diapositiva:**
    * Definici칩n de $\alpha$ y $\beta$ en un nodo `s`:
        $$ \alpha_{s}=max_{s^{\prime}\in ancestros(s)\cup\{s\}}a_{s^{\prime}} $$
        $$ \beta_{s}=min_{s^{\prime}\in ancestros(s)\cup\{s\}}b_{s^{\prime}} $$
    * Condici칩n de poda: Ocurre si el intervalo $[\alpha_s, \beta_s]$ no es v치lido, es decir, $\alpha_s \ge \beta_s$.
    * Ejemplo de la condici칩n: $\alpha_{D}=max\{6,3\}=6$ y $\beta_{D}=min\{8,5\}=5$. Como $6 \ge 5$, se poda.

* **Flashcards 游:**
    * **Pregunta:** 쮺u치l es la condici칩n matem치tica que permite realizar una poda Alfa-Beta?
        > **Respuesta:** Se puede podar una rama cuando $\alpha \ge \beta$.

---

### **Diapositiva 6: Efectividad de la Poda 풤-**

* **Resumen Estricto:**
    * La eficiencia de la poda depende cr칤ticamente del **orden** en que se exploran los nodos hijos.
    * **Mejor caso:** Si siempre se exploran primero las mejores jugadas, la complejidad se reduce a $O(b^{d/2})$. Esto permite en la pr치ctica buscar el doble de profundo con los mismos recursos.
    * **Peor caso:** Si se exploran las peores jugadas primero, no se realiza ninguna poda y la complejidad sigue siendo $O(b^d)$, igual que Minimax simple.

* **Ecuaciones de la Diapositiva:**
    * Complejidad en el peor orden: $O(b^{d})$
    * Complejidad en el mejor orden: $O(b^{d/2})$
    * Complejidad en orden aleatorio: $O(b^{3d/4})$ *(Corregido de la diapositiva que ten칤a un typo)*.

* **Flashcards 游:**
    * **Pregunta:** 쮺칩mo afecta el orden de evaluaci칩n de movimientos a la poda Alfa-Beta?
        > **Respuesta:** Un buen orden (explorar las mejores jugadas primero) maximiza la cantidad de podas y mejora dr치sticamente el rendimiento. Un mal orden puede no producir ninguna poda.

---

### **Diapositiva 7 y 8: Funciones de Evaluaci칩n**

* **Resumen Estricto:**
    * Para juegos con 치rboles demasiado grandes, se introduce una t칠cnica para cortar la b칰squeda a una **profundidad m치xima ($d_{max}$)**.
    * Cuando se alcanza esta profundidad, en lugar de tener un valor terminal (victoria/derrota), se utiliza una **Funci칩n de Evaluaci칩n ($Eval(s)$)** que estima qu칠 tan buena es esa posici칩n.
    * El algoritmo Minimax se ejecuta sobre este 치rbol de profundidad limitada, usando los valores de `Eval(s)` como si fueran los de las hojas. El resultado es un valor Minimax aproximado.

* **Ecuaciones de la Diapositiva (Recurrencia de Minimax con L칤mite de Profundidad):**
    * $V(s,d) = \begin{cases} Utilidad(s) & \text{si EsFinal(s)} \\ Eval(s) & \text{si } d=0 \\ max_{a} V(Suc(s,a), d-1) & \text{si Jugador(s)=Agente} \\ min_{a} V(Suc(s,a), d-1) & \text{si Jugador(s)=Oponente} \end{cases}$

* **Flashcards 游:**
    * **Pregunta:** 쮺u치l es el prop칩sito de una funci칩n de evaluaci칩n en el contexto de la b칰squeda en 치rboles de juego?
        > **Respuesta:** Permitir que el algoritmo tome una decisi칩n sin explorar el 치rbol hasta el final. Estima el valor de una posici칩n a una profundidad de corte predefinida.

---

### **Diapositiva 9: Dise침o de Funciones de Evaluaci칩n**

* **Resumen Estricto:**
    * Se listan tres propiedades deseables para una buena funci칩n de evaluaci칩n `Eval(s)`:
        1.  Debe ser consistente con la utilidad real en estados terminales (un estado de victoria debe tener mayor valor que uno de empate, y este mayor que uno de derrota).
        2.  Debe ser computacionalmente r치pida, ya que se calcula muchas veces.
        3.  Su valor para estados no terminales debe estar fuertemente correlacionado con la probabilidad real de ganar desde ese estado.

* **Ecuaciones de la Diapositiva:**
    * $Eval(win) > Eval(draw) > Eval(loss)$

---

### **Diapositiva 10 y 11: Ejemplo de Funci칩n de Evaluaci칩n para Ajedrez**

* **Resumen Estricto:**
    * Se propone una funci칩n de evaluaci칩n simple para ajedrez basada en el **valor material** de las piezas.
    * Esta primera funci칩n es defectuosa porque no distingue entre un jaque mate y un empate si el material es el mismo.
    * Se redefine para incluir un t칠rmino muy grande ($\aleph$) que representa la victoria o derrota, haciendo que el resultado del juego sea el factor m치s importante, y el material un criterio de desempate.

* **Ecuaciones de la Diapositiva:**
    * Funci칩n simple:
        $$ Eval(s)=9(D_{a}-D_{o})+5(T_{a}-T_{o}) + \dots $$
    * Funci칩n redefinida y mejorada:
        $$ Eval(s)=\aleph(R_{a}(s)-R_{o}(s)) + 9(D_{a}(s)-D_{o}(s)) + \dots $$

---

### **Diapositiva 12: Enfoque General de Funciones de Evaluaci칩n**

* **Resumen Estricto:**
    * Se presenta un enfoque general y moderno: definir `Eval` como una **funci칩n lineal ponderada de caracter칤sticas (features)**.
    * La funci칩n extrae un vector de caracter칤sticas $\phi(s)$ de un estado `s`, y calcula una puntuaci칩n como el producto punto con un vector de pesos `w`.

* **Ecuaciones de la Diapositiva:**
    * Funci칩n lineal de evaluaci칩n:
        $$ Eval(s;w)=w\cdot\phi(s)=\sum_{k=1}^{K}w_{k}\phi_{k}(s) $$
    * Ejemplo de vector de caracter칤sticas $\phi(s)$ para ajedrez:
        $$ \phi(s) = (\phi_1(s), \phi_2(s), \dots) = (R_{a}-R_{o}, D_{a}-D_{o}, \dots) $$
    * Ejemplo de vector de pesos `w` y c치lculo final:
        $$ w = (\aleph,9,5,3,1) \implies Eval(s)=w \cdot \phi(s) $$

* **Flashcards 游:**
    * **Pregunta:** 쯈u칠 es una funci칩n de evaluaci칩n basada en caracter칤sticas?
        > **Respuesta:** Es una funci칩n que no eval칰a el estado directamente, sino que extrae un conjunto de propiedades medibles (caracter칤sticas o *features*) y las combina de forma ponderada para producir una puntuaci칩n.

---

### **Diapositiva 13, 14 y 15: Implementaci칩n**

* **Resumen Estricto:**
    * Se muestra pseudo-c칩digo para la implementaci칩n de un agente que juega usando Minimax.
    * **Diap. 13:** El bucle principal del juego, donde en cada turno se le pide a un jugador que elija una acci칩n.
    * **Diap. 14:** La funci칩n `p.action`, que clona el estado actual del juego para no modificarlo y llama a la funci칩n `minimax` para planificar.
    * **Diapositiva 15:** La funci칩n recursiva `p.minimax`, que implementa la l칩gica de Minimax con l칤mite de profundidad y funci칩n de evaluaci칩n.

* **Ecuaciones de la Diapositiva (Pseudo-c칩digo clave de la Diap. 15):**
    ```
    function minimax(G, p', d):
        if G.EsFinal(): return None, G.Utilidad(p)
        if d == 0: return None, G.Eval(p)
        
        // ... calcular valores V de los sucesores recursivamente ...
        
        if p == p': // Turno del Agente (MAX)
            return arg max V, max V
        else: // Turno del Oponente (MIN)
            return arg min V, min V
    ```

* **Flashcards 游:**
    * **Pregunta:** 쮺u치les son los dos casos base (condiciones de parada) de la funci칩n recursiva de Minimax?
        > **Respuesta:** 1. Si el estado es terminal (fin del juego). 2. Si se ha alcanzado la profundidad m치xima de b칰squeda (`d=0`).

---

### **Diapositiva 16: Bibliograf칤a**

* **Resumen Estricto:**
    * Se recomienda el Cap칤tulo 5 del libro "Inteligencia Artificial: Un Enfoque Moderno" de Russell y Norvig como referencia principal.