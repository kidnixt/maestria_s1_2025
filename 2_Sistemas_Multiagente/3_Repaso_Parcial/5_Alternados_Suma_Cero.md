# 游닄 Gu칤a de Estudio Detallada: Juegos Alternados y Minimax 鮫勇

---

### **Diapositiva 1: Portada**

* **Resumen Estricto:**
    * **Curso:** Sistemas Multiagente.
    * **Tema:** Juegos Alternados de Suma Cero para 2 Jugadores.
    * **Autor:** Sergio Yovine, Universidad ORT Uruguay.
    * **Fecha:** 30 de abril de 2025.

---

### **Diapositiva 2: Un Juego Alternado Sencillo**

* **Resumen Estricto:**
    * Se introduce un juego simple de 2 turnos para 2 jugadores.
        * **Turno 1 (Ustedes):** Eligen una de tres cajas (A, B, C). Su objetivo es maximizar el resultado final.
        * **Turno 2 (Yo):** Elijo un n칰mero de dentro de la caja que ustedes eligieron. Mi objetivo es minimizar el resultado final (impl칤cito por ser un juego de suma cero).
    * Se muestran los n칰meros contenidos en cada caja.

* **Ejemplo Did치ctico:**
    * Esto es la base de los juegos de estrategia por turnos, como el ajedrez. Un jugador hace un movimiento, y el otro responde. Tu elecci칩n inicial (qu칠 caja elegir) depende de c칩mo crees que yo responder칠. Si eliges la caja C que contiene {-5, 15}, 쯤u칠 n칰mero crees que elegir칠 yo, sabiendo que quiero minimizar tu puntuaci칩n? Probablemente el -5. Debes anticipar mi jugada para hacer la tuya.

* **Flashcards 游:**
    * **Pregunta:** 쯈u칠 significa que un juego sea "alternado"?
        > **Respuesta:** Que los jugadores no act칰an simult치neamente, sino que toman turnos para hacer sus movimientos.

---

### **Diapositiva 3: 츼rbol de Juego**

* **Resumen Estricto:**
    * Se visualiza el "juego de las cajas" como un **치rbol de juego**.
    * La idea es que cada nodo del 치rbol representa un punto de decisi칩n para un jugador.
    * Los nodos hoja (al final del 치rbol) representan los resultados finales posibles del juego.

* **Ejemplo Did치ctico:**
    * El nodo ra칤z (la cima del 치rbol) es el turno del Jugador 1 (el maximizador). Sus tres ramas son las acciones A, B y C.
    * Cada uno de esos tres nodos hijos es un punto de decisi칩n para el Jugador 2 (el minimizador). Desde el nodo "A", el Jugador 2 tiene dos ramas que llevan a las hojas -50 y 50.
    * Este 치rbol representa todas las secuencias posibles del juego.

* **Flashcards 游:**
    * **Pregunta:** En un 치rbol de juego, 쯤u칠 representan los nodos hoja?
        > **Respuesta:** Los estados terminales del juego y sus utilidades o resultados finales.

---

### **Diapositiva 4: Definici칩n Formal de un Juego Alternado**

* **Resumen Estricto:**
    * Se definen formalmente los componentes de un juego alternado de suma cero para dos jugadores ({Agente, Oponente}).
    * Incluye un estado inicial, las acciones posibles en cada estado, una funci칩n sucesor (determinista), una funci칩n para saber si un estado es terminal, una funci칩n de utilidad (desde la perspectiva del Agente) y una funci칩n que indica a qu칠 jugador le toca jugar en cada estado.

* **Ecuaciones de la Diapositiva (Definiciones de Componentes):**
    * Estado inicial: $s_{start}$
    * Acciones posibles: $Acciones(s)$
    * Estado siguiente: $Suc(s,a)$
    * Comprobaci칩n de estado final: $EsFinal(s)$
    * Utilidad del agente en un estado final: $Utilidad(s)$
    * Jugador activo en el estado `s`: $Jugador(s) \in \{\text{Agente, Oponente}\}$

* **Flashcards 游:**
    * **Pregunta:** 쮺u치l es la diferencia clave entre la funci칩n de transici칩n `T` de un juego estoc치stico y la funci칩n `Suc(s,a)` de un juego alternado (determinista)?
        > **Respuesta:** `T` es probabil칤stica (devuelve una distribuci칩n de probabilidad sobre los siguientes estados). `Suc(s,a)` es determinista (devuelve un 칰nico estado sucesor).

---

### **Diapositiva 5: Pol칤ticas**

* **Resumen Estricto:**
    * Se define qu칠 es una pol칤tica o estrategia en este contexto.
    * **Pol칤tica pura o determin칤stica:** Un mapeo de cada estado a una 칰nica acci칩n. Te dice exactamente qu칠 hacer en cada situaci칩n.
    * **Pol칤tica mixta o estoc치stica:** Un mapeo de cada estado a una distribuci칩n de probabilidad sobre las acciones. Te dice con qu칠 probabilidad jugar cada acci칩n posible.

* **Ecuaciones de la Diapositiva:**
    * Pol칤tica pura: $\pi_{p}(s)\in Acciones(s)$
    * Pol칤tica mixta: $\pi_{p}(s,a)\in[0,1]$ (tal que $\sum_a \pi_p(s,a) = 1$)

* **Flashcards 游:**
    * **Pregunta:** 쯈u칠 es una pol칤tica en el contexto de un 치rbol de juego?
        > **Respuesta:** Es un "libro de jugadas" completo que le dice a un agente qu칠 acci칩n tomar (o con qu칠 probabilidad tomar cada acci칩n) para cualquier estado posible del juego.

---

### **Diapositiva 6: Evaluando un Juego (Ejemplo)**

* **Resumen Estricto:**
    * Se muestra c칩mo calcular el valor de un juego si las pol칤ticas de ambos jugadores son fijas.
    * **Pol칤tica del Agente:** Elegir siempre la caja A.
    * **Pol칤tica del Oponente:** En cualquier caja, elegir cada n칰mero con un 50% de probabilidad (uniforme).
    * El valor esperado resultante para el agente al inicio del juego es 0.

* **Ecuaciones de la Diapositiva:**
    * $\pi_{agente}(s_{start})=A$
    * $\pi_{oponente}(s,a)=0,5$
    * $V_{\pi_{agente},\pi_{oponente}}(s_{start})=0$

* **Ejemplo Did치ctico Extendido:**
    * El agente est치 obligado por su pol칤tica a elegir la rama "A".
    * Ahora es el turno del oponente. Su pol칤tica es estoc치stica: elige la rama "-50" con probabilidad 0.5 y la rama "50" con probabilidad 0.5.
    * El valor de este nodo de decisi칩n del oponente es el valor esperado:
        $$ (0.5 \times -50) + (0.5 \times 50) = -25 + 25 = 0 $$
    * Como la primera acci칩n del agente lleva a un nodo con valor 0, el valor total del juego bajo estas pol칤ticas es 0.

---

### **Diapositiva 7: Recurrencia de Evaluaci칩n de Juegos**

* **Resumen Estricto:**
    * Se presenta la f칩rmula recursiva general para calcular el valor de un estado `s` para cualquier par de pol칤ticas.
    * Si `s` es final, su valor es `Utilidad(s)`.
    * Si no es final, su valor depende de a qui칠n le toque jugar:
        * Si juega el Agente, se promedian los valores de los estados sucesores seg칰n la pol칤tica del Agente.
        * Si juega el Oponente, se promedian seg칰n la pol칤tica del Oponente.

* **Ecuaciones de la Diapositiva:**
    * $V_{\pi_{agente},\pi_{oponente}}(s) = \begin{cases} Utilidad(s) & \text{si EsFinal(s)} \\ \sum_{a \in Acciones(s)} \pi_{agente}(s,a) V_{\pi_{agente},\pi_{oponente}}(Suc(s,a)) & \text{si Jugador(s)=Agente} \\ \sum_{a \in Acciones(s)} \pi_{oponente}(s,a) V_{\pi_{agente},\pi_{oponente}}(Suc(s,a)) & \text{si Jugador(s)=Oponente} \end{cases}$

---

### **Diapositiva 8 y 9: ExpectiMax**

* **Resumen Estricto:**
    * Se introduce el algoritmo **ExpectiMax**, que se usa cuando el Agente (MAX) es racional, pero el oponente no es un minimizador perfecto, sino que juega de forma estoc치stica (en este caso, al azar).
    * El Agente (nodo MAX) elige la acci칩n que lleva al sucesor con el **m치ximo** valor.
    * El Oponente (nodo CHANCE) no elige, sino que sus nodos se eval칰an calculando el **valor esperado (promedio)** de sus sucesores.
    * Para el juego de las cajas, el valor ExpectiMax es 5, y la acci칩n 칩ptima para el agente es elegir la caja C.

* **Ecuaciones de la Diapositiva 9 (Recurrencia de ExpectiMax):**
    * $V_{expmax}(s) = \begin{cases} Utilidad(s) & \text{si EsFinal(s)} \\ max_{a \in Acciones(s)} V_{expmax}(Suc(s,a)) & \text{si Jugador(s)=Agente} \\ \sum_{a \in Acciones(s)} \pi_{oponente}(s,a) V_{expmax}(Suc(s,a)) & \text{si Jugador(s)=Oponente} \end{cases}$
    * *(Nota: Se asume que $V_{expmax}$ es una abreviaci칩n de $V_{\pi_{expmax},\pi_{oponente}}$)*

* **Ejemplo Did치ctico Extendido:**
    1.  **Evaluar Nodos del Oponente (Promedio):**
        * Valor de la caja A: $(-50 + 50) / 2 = 0$.
        * Valor de la caja B: $(1 + 3) / 2 = 2$.
        * Valor de la caja C: $(-5 + 15) / 2 = 5$.
    2.  **Evaluar Nodo del Agente (M치ximo):**
        * El agente ve los posibles resultados: 0, 2, 5.
        * Elige el m치ximo: **5**. Por lo tanto, su acci칩n 칩ptima es elegir la caja C.

---

### **Diapositiva 10 y 11: MiniMax**

* **Resumen Estricto:**
    * Se introduce el algoritmo **MiniMax**, que se usa cuando el Agente (MAX) juega contra un Oponente perfecto y racional (MIN).
    * El Agente (nodo MAX) elige la acci칩n que lleva al sucesor con el **m치ximo** valor.
    * El Oponente (nodo MIN) elige la acci칩n que lleva al sucesor con el **m칤nimo** valor.
    * Para el juego de las cajas, el valor Minimax es 1, y la acci칩n 칩ptima para el agente es elegir la caja B.

* **Ecuaciones de la Diapositiva 11 (Recurrencia de MiniMax):**
    * $V_{minimax}(s) = \begin{cases} Utilidad(s) & \text{si EsFinal(s)} \\ max_{a \in Acciones(s)} V_{minimax}(Suc(s,a)) & \text{si Jugador(s)=Agente} \\ min_{a \in Acciones(s)} V_{minimax}(Suc(s,a)) & \text{si Jugador(s)=Oponente} \end{cases}$

* **Ejemplo Did치ctico Extendido:**
    1.  **Evaluar Nodos del Oponente (M칤nimo):**
        * Valor de la caja A: $min(-50, 50) = -50$.
        * Valor de la caja B: $min(1, 3) = 1$.
        * Valor de la caja C: $min(-5, 15) = -5$.
    2.  **Evaluar Nodo del Agente (M치ximo):**
        * El agente ve los resultados garantizados que el oponente le dejar치: -50, 1, -5.
        * Elige el m치ximo de estos peores casos: **1**. Por lo tanto, su acci칩n 칩ptima es elegir la caja B.

* **Flashcards 游:**
    * **Pregunta:** 쮺u치l es la diferencia fundamental en c칩mo se eval칰an los nodos del oponente en ExpectiMax y en MiniMax?
        > **Respuesta:** En ExpectiMax, los nodos del oponente se eval칰an con un **promedio** (valor esperado). En MiniMax, se eval칰an con el **m칤nimo**.
    * **Pregunta:** 쮺u치ndo deber칤as usar MiniMax y cu치ndo ExpectiMax?
        > **Respuesta:** Usa MiniMax si juegas contra un oponente perfectamente racional que intentar치 minimizar tu puntuaci칩n. Usa ExpectiMax si juegas contra un oponente que act칰a de forma aleatoria o no 칩ptima.

---

### **Diapositiva 12, 13 y 14: Propiedades de MiniMax**

* **Resumen Estricto:**
    * **(Diap. 12)** La pol칤tica minimax del agente es una mejor respuesta contra la pol칤tica minimizadora del oponente. No puedes mejorar tu resultado si el oponente juega perfecto.
    * **(Diapositiva 13)** El valor minimax es una **cota inferior**: jugando la estrategia minimax, tienes garantizado obtener *al menos* ese valor, sin importar lo que haga el oponente (incluso si juega mal y te beneficia).
    * **(Diapositiva 14)** En general, la pol칤tica minimax **no es la mejor respuesta** contra un oponente no 칩ptimo. Es demasiado pesimista. Contra un oponente aleatorio, la pol칤tica Expectimax da un mejor resultado.

* **Ecuaciones Clave:**
    * $V_{\pi_{minimax},\pi_{min}}(s) \ge V_{\pi_{agente},\pi_{min}}(s)$ (No puedes mejorar contra un oponente perfecto).
    * $V_{\pi_{minimax},\pi_{min}}(s) \le V_{\pi_{minimax},\pi_{oponente}}(s)$ (Tu resultado ser치 al menos el valor minimax, y posiblemente mejor si el oponente se equivoca).
    * En el ejemplo: $V_{\pi_{minimax},\pi_{oponente}}(s) = 2 < V_{\pi_{expmax},\pi_{oponente}}(s) = 5$ (Expectimax es mejor contra un oponente aleatorio).

---

### **Diapositiva 15, 16 y 17: Introduciendo Azar (ExpectiMiniMax)**

* **Resumen Estricto:**
    * Se introduce un elemento de azar en el juego: una moneda que puede cambiar la caja elegida.
    * Esto a침ade un tercer tipo de nodo al 치rbol: **Nodos de Azar (Chance)**.
    * El algoritmo para resolver estos juegos es **ExpectiMiniMax**.
    * **(Diapositiva 17)** La recurrencia es una combinaci칩n de los anteriores: los nodos del Agente maximizan, los del Oponente minimizan y los nodos de Azar calculan el valor esperado (promedio).

* **Ecuaciones de la Diapositiva 17 (Recurrencia ExpectiMiniMax):**
    * $V(s) = \begin{cases} Utilidad(s) & \text{si EsFinal(s)} \\ max_{a} V(Suc(s,a)) & \text{si Jugador(s)=Agente} \\ min_{a} V(Suc(s,a)) & \text{si Jugador(s)=Oponente} \\ \sum_{a} \pi_{azar}(s,a) V(Suc(s,a)) & \text{si Jugador(s)=Moneda} \end{cases}$

* **Flashcards 游:**
    * **Pregunta:** 쯈u칠 tipo de nodo se a침ade al 치rbol de juego para modelar eventos aleatorios?
        > **Respuesta:** Un Nodo de Azar (Chance node).
    * **Pregunta:** 쮺칩mo se calcula el valor de un Nodo de Azar en el algoritmo ExpectiMiniMax?
        > **Respuesta:** Se calcula el valor esperado, es decir, el promedio ponderado de los valores de sus nodos hijos, usando las probabilidades del evento aleatorio.

---

### **Diapositiva 18: Bibliograf칤a**

* **Resumen Estricto:**
    * Se recomienda el Cap칤tulo 5 del libro "Inteligencia Artificial: Un Enfoque Moderno" de Russell y Norvig como referencia principal para estos temas.