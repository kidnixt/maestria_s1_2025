# ğŸ·ï¸ Etiquetado de Datos

## ğŸ¯ Objetivo de la clase

Comprender cÃ³mo influye el proceso de **etiquetado de datos** en la calidad del modelo de ML.  
Explorar **tipos de etiquetas, fuentes, estrategias de etiquetado, ambigÃ¼edades y tÃ©cnicas avanzadas** como Active Learning, Transfer Learning, Weak Supervision y Data Augmentation.

> "f(ğŸ’©) = ğŸ’©" â†’ Si las etiquetas son malas, los resultados tambiÃ©n lo serÃ¡n.

---

## ğŸ” Ciclo de gestiÃ³n de datos

Recolectar â†’ Procesar â†’ Almacenar â†’ Recuperar  
El etiquetado se ubica dentro de este ciclo y es **clave para garantizar datos Ãºtiles**.

---

## ğŸ§© Fuentes de datos etiquetados

1. **Datos propios**
   - Â¿QuÃ© tipo de datos ya tengo?
   - Â¿Con quÃ© frecuencia se actualizan?
   - Â¿Ya estÃ¡n etiquetados o hay que hacerlo?

2. **Etiquetado manual**
   - Â¿QuiÃ©n etiqueta? Â¿In-house, tercerizados, crowdsourced?
   - Â¿Requiere expertos del dominio o generalistas?

3. **Compra de datasets**
   - Ej: imÃ¡genes mÃ©dicas ya anotadas, bases de texto etiquetado.

---

## âš–ï¸ Problemas comunes en los datos

| CategorÃ­a          | DesafÃ­os clave                                                   |
|--------------------|------------------------------------------------------------------|
| No estructurados   | DifÃ­ciles de procesar, etiquetar requiere juicio humano          |
| Estructurados      | Normalmente mÃ¡s fÃ¡ciles de etiquetar, pero puede haber ruido     |
| Small data         | Pocos ejemplos, difÃ­cil generalizar                              |
| Big data           | Ruido, inconsistencias, etiquetar manualmente es inviable        |

> Ej:  
> - 50 millones de datos para reconocimiento de voz = Big Data  
> - 100 imÃ¡genes para inspecciÃ³n visual en manufactura = Small Data


![[Pasted image 20250604164209.png]]


## âœ… Calidad vs Cantidad

|                     | Etiquetas ruidosas  | Etiquetas limpias      |
|---------------------|---------------------|-------------------------|
| **Pocos datos**     | âŒ Mucho overfitting | âœ… Mejor opciÃ³n posible |
| **Muchos datos**    | ğŸ¤” Mejora, pero puede daÃ±ar | âœ… Ideal, aunque costoso |
![[Pasted image 20250604164257.png]]
---

## ğŸ–¼ï¸ Ejemplos prÃ¡cticos de etiquetado

- Bounding boxes en imÃ¡genes: marcar iguanas ğŸ¦
![[Pasted image 20250604164321.png]]


- DetecciÃ³n de fallas en smartphones
![[Pasted image 20250604164348.png]]


- Captchas: segmentaciÃ³n manual de texto/imÃ¡genes

---

## ğŸ‘¥ VotaciÃ³n y crowdsourcing

- Etiquetadores mÃºltiples â‰  siempre mismo resultado
- Soluciones:
  - Etiquetador extra decide
  - Clase neutral
  - Voto por mayorÃ­a

> En tareas multilabel u object detection tambiÃ©n aplica este problema.

---

## ğŸ§  Dilemas en el etiquetado humano

- Â¿QuiÃ©n es el ground truth?
- Â¿QuÃ© es precisiÃ³n si hay mÃºltiples opiniones?
- Â¿CÃ³mo se entrena a los etiquetadores?
- Â¿QuÃ© protocolo deben seguir?

### Consideraciones Claves en el etiquetado humano

- Caro, especialmente si se precisan expertos en el dominio.
- Es muy lento.
- Privacidad de los datos es un gran problema.
- MÃºltiples fuente de datos etiquetados.
- La ambigÃ¼edad es un problema grande. 

---

## ğŸ‘¤ Tipos de etiquetadores

| Tipo             | DescripciÃ³n                                         |
|------------------|-----------------------------------------------------|
| Expertos         | Dominio especializado (ej. mÃ©dicos)                 |
| Generalistas     | Personal tÃ©cnico entrenado para tareas especÃ­ficas |
| Crowdsourcing    | Usuarios comunes o plataformas externas             |

---

## ğŸ” AmbigÃ¼edad y multiplicidad de etiquetas

Para mitigarla:
- Usar varios etiquetadores
- Definir claramente el problema
- Establecer un protocolo claro
- Entrenar a los etiquetadores
- Registrar decisiones y trazabilidad

---

## ğŸ§  Human Level Performance (HLP)

- HLP se usa como benchmark: Â¿el modelo rinde igual o mejor que un humano?
- Si el ground truth fue generado por humanos, HLP = nivel de acuerdo entre etiquetadores.
- Si el ground truth viene de fuentes externas (ej: biopsia), el HLP es mÃ¡s objetivo.

---

## ğŸ¯ Etiquetas naturales

Cuando el target **surge de forma automÃ¡tica** del sistema.

### Ejemplos:
- Tiempo estimado de llegada (ETA)
- Clicks, vistas, tiempo de interacciÃ³n
- Precio de una acciÃ³n

> âš ï¸ A veces implican sesgos (ej: click â‰  preferencia real)

---

## ğŸ–±ï¸ Feedback en sistemas de recomendaciÃ³n

| Tipo      | Ejemplos                                      |
|-----------|-----------------------------------------------|
| ExplÃ­cito | Ratings, reseÃ±as, NPS                         |
| ImplÃ­cito | Clicks, vistas, tiempo de permanencia         |

---

## âš™ï¸ ML en producciÃ³n vs academia (recordatorio)

| Academia                       | ProducciÃ³n                             |
|-------------------------------|----------------------------------------|
| Dataset limpio, fijo          | Datos dinÃ¡micos, sucios                |
| MÃ©tricas acadÃ©micas (F1, acc) | Restricciones reales (latencia, costo) |
| SOTA                          | Simplicidad, mantenibilidad            |

---

## ğŸ“‰ Cuello de botella: los datos

| Etapa           | Tiempo tÃ­pico  | Impacto en rendimiento |
|-----------------|----------------|-------------------------|
| Obtener datos   | Semanas        | Alta                    |
| Ajustar modelo  | DÃ­as           | Baja                    |

> ğŸš€ Mejor invertir en buenos datos que en fine-tuning eterno.

![[Pasted image 20250604165258.png]]

---

## â±ï¸ Â¿CuÃ¡nto tiempo dedicar al etiquetado?

En lugar de preguntar â€œÂ¿cuÃ¡ntos datos necesito?â€,  
preguntar: **Â¿cuÃ¡ntos datos puedo etiquetar en X dÃ­as?**

> Este cambio de mentalidad permite iterar mÃ¡s rÃ¡pido.

---

## ğŸ§  TÃ©cnicas avanzadas de etiquetado

| MÃ©todo              | Â¿CÃ³mo funciona?                                  | Â¿Necesita ground truth? |
|---------------------|--------------------------------------------------|--------------------------|
| Semi-supervision    | Propaga etiquetas desde un conjunto pequeÃ±o      | âœ…                       |
| Transfer learning   | Usa modelos preentrenados en otras tareas        | âœ…/âŒ                    |
| Weak supervision    | Usa reglas, keywords, modelos externos           | âŒ                      |
| Active learning     | Elige quÃ© datos conviene etiquetar               | âœ…                       |

---

## ğŸ”„ Semi-supervised learning

- Propaga etiquetas a partir de ejemplos con etiquetas
- Usa estructura o similitud entre datos (ej: clustering)

![[Pasted image 20250604165403.png]]

> Ejemplo: Label Propagation (Iscen et al., 2019)

---

## ğŸ” Transfer Learning

- Modelos entrenados en tareas grandes y generales (ej: BERT, ResNet)
- Se reutilizan en tareas especÃ­ficas: anÃ¡lisis de sentimiento, detecciÃ³n de fallas, etc.

Ventajas:
- Reduce necesidad de datos etiquetados
- Ahorra cÃ³mputo

Â¿Necesitan Ground Truth?
- **No**, para zero-shot
- **Si** para transfer-learning, pero menos que entrenar desde cero

---

## ğŸ¤– Weak Supervision

Etiquetado ruidoso basado en heurÃ­sticas:

- Palabras clave
- Regex
- Bases externas
- Modelos anteriores

Ej: Si una nota mÃ©dica menciona â€œneumonÃ­aâ€, marcar como emergencia

> Herramientas: **Snorkel**

![[Pasted image 20250604165433.png]]

![[Pasted image 20250604165444.png]]


---

## ğŸ§  Active Learning

El modelo pide etiquetas para **los ejemplos mÃ¡s informativos**:

- Los que menos confianza tiene
- Donde hay mÃ¡s desacuerdo entre modelos
- Donde el modelo comete errores frecuentes

> Ideal cuando etiquetar es caro

![[Pasted image 20250604165501.png]]

---

### TÃ©cnicas de Active Learning

- **Margen:** ejemplos con baja diferencia entre clases mÃ¡s probables
- **Clustering:** samplea de clusters bien formados para cubrir todo el espacio de los datos
- **Query-by-committee:** usar un ensemble y etiquetar donde discrepan
- **Por regiones:** aplicar tÃ©cnicas distintas en distintas zonas del espacio de datos

---

## â• Data Augmentation

> Crear nuevos datos sintÃ©ticos preservando las etiquetas

### Objetivos:
- Aumentar el dataset
- Mejorar robustez y generalizaciÃ³n
- Resistir ataques adversarios

---

### TÃ©cnicas en imÃ¡genes

- RotaciÃ³n, flipping, cropping
- Brillo, saturaciÃ³n, contraste
- Cortar zonas (Cutout, GridMask)
- Mezclar imÃ¡genes (Mixup, CutMix)

---

### TÃ©cnicas en texto

- Reemplazo de sinÃ³nimos
- Plantillas con slots
  - Ej: â€œBusco restaurante [tipo] en [barrio]â€

> TambiÃ©n se usan LLMs para generar variantes
