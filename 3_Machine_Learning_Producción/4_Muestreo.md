#  Muestreo y Repaso

Esta clase se enfoca en la importancia cr铆tica de los datos en el ciclo de vida de un proyecto de Machine Learning, profundizando en c贸mo el **muestreo adecuado** y la gesti贸n de **sesgos** son fundamentales para el 茅xito en producci贸n.

##  Ciclo de Vida de un Proyecto de ML y Gesti贸n de Datos

El diagrama del ciclo de vida de un proyecto de ML destaca la **Gesti贸n de Datos** como un componente central. Esta gesti贸n es crucial en todas las etapas, desde la definici贸n del alcance del proyecto (Project Scoping) hasta el despliegue (Deployment) y el monitoreo y mantenimiento del modelo (Monitoring & Maintenance).
![[Pasted image 20250717051726.png]]

##  Datos de Entrenamiento: Fundamento Cr铆tico

La preparaci贸n de datos es esencial para el **Data Science**. Los datos en la realidad suelen ser complejos y son el factor determinante en cualquier operaci贸n de ML. Es vital tener **"ojo con los datos"** porque pueden estar potencialmente sesgados debido a c贸mo se recolectan, el m茅todo de muestreo utilizado, la forma en que fueron etiquetados o porque la realidad misma cambia.

## И Muestreo: Una Clave en el Flujo de Trabajo de ML

El muestreo es una parte clave del flujo de trabajo de ML, fundamental para:
* Obtener datos de entrenamiento.
* Validar Pruebas de Concepto (PoC).
* Crear divisiones de datos para entrenamiento, validaci贸n y prueba (`train/val/test splits`).
* Monitorear los eventos del sistema de ML.

Comprender y aplicar correctamente las diferentes t茅cnicas de muestreo ayuda a **evitar sesgos** en los modelos.

### Tipos de Muestreo

Existen dos categor铆as principales de muestreo:
* **No probabil铆stico**
* **Aleatorio**

### Muestreo No Probabil铆stico

Este tipo de muestreo se caracteriza por estar **"lleno de sesgos"** y, en general, **NO es bueno para ML** en producci贸n debido a su falta de confiabilidad. Sin embargo, puede ser una manera r谩pida y f谩cil de experimentar.

* **Por conveniencia:** Se basa en la disponibilidad de los datos.
* **Snowball (bola de nieve):** Se parte de muestras ya obtenidas para conseguir m谩s a partir de ellas (ejemplo: web scraping).
* **Juicio de Expertos:** Se basa en la opini贸n o selecci贸n de expertos en el dominio.
* **Cuotas:** Se basa en establecer cuotas por segmento de los datos (ejemplo: encuestas separadas por franja etaria o nivel socio-econ贸mico).

### Muestreo Aleatorio

* **Pros:** Es m谩s f谩cil de implementar.
* **Contras:** Se complica cuando hay categor铆as raras o poco frecuentes en los datos.

### Muestreo Estratificado

Consiste en obtener muestras por **grupo de datos (estrato)**.
* Asegura que todas las clases sean muestreadas
* Se puede obtener en la misma proporci贸n para representar la poblaci贸n original.
* Se complica con problemas de *multi-label*.

![[Pasted image 20250530132207.png]]

### Muestreo Ponderado

A cada muestra se le asigna una **probabilidad de ser seleccionada**.
* Permite definir de antemano una probabilidad por clase (ejemplo: dar mayor peso a datos m谩s recientes si se consideran m谩s importantes).
* Aprovecha el conocimiento del dominio para ajustar la distribuci贸n de los datos si no est谩 alineada con la realidad, cambiando los pesos asignados.

### Reservoir Sampling

Particularmente 煤til para **datos de streaming** (flujo continuo de datos) y cuando existen limitaciones de memoria (ejemplo: procesamiento de tweets).
* **Objetivo:** Asegurar que cada 铆tem tenga la misma probabilidad de ser seleccionado.
* Se mantiene una premisa o aserci贸n invariante en todo momento.
* **Algoritmo R (soluci贸n con array de reserva):**
    * Los primeros `K` 铆tems van directamente a un array de reserva.
    * Para cada nuevo elemento `i` (donde `i > K`), se genera un n煤mero aleatorio `j` entre 1 e `i`.
    * Si `j < K`, el elemento `j` en la reserva es reemplazado por el nuevo elemento; de lo contrario, el nuevo elemento se descarta.
* Esto implica que cada elemento `n` tiene una probabilidad de `k/n` de entrar en la reserva.

![[Pasted image 20250530132335.png]]

##  Datos No Balanceados

Los modelos de Machine Learning funcionan mejor con **distribuciones de datos balanceadas**. Las distribuciones desequilibradas, donde algunas clases tienen muchos m谩s ejemplos que otras, complican el rendimiento del modelo.

![[Pasted image 20250530132351.png]]

### Formas de Resolver Problemas con Datos No Balanceados

Existen tres enfoques principales para abordar los datos no balanceados:
1.  Eligiendo las **m茅tricas correctas**.
2.  Atacando la **distribuci贸n de los datos**.
3.  Utilizando **m茅todos a nivel de algoritmo**.

#### 1. Eligiendo las M茅tricas Correctas

Cuando los datos est谩n desbalanceados, la m茅trica de **Accuracy (precisi贸n general)** puede ser enga帽osa. Un modelo puede tener una alta precisi贸n simplemente por predecir la clase mayoritaria.

![[Pasted image 20250530132502.png]]

Es fundamental utilizar m茅tricas m谩s adecuadas como:
* **Precision**.
* **Recall**.
* **F1-Score** (una media arm贸nica de Precision y Recall).
* **AUC (Area Under the ROC Curve)**. Un valor de AUC m谩s cercano a 1.0 indica un mejor rendimiento del modelo, siendo 0.5 similar a una predicci贸n aleatoria.
![[Pasted image 20250530132519.png]]
#### 2. Atacando la Distribuci贸n de Datos


Se busca modificar el dataset para balancear las clases:
* **Undersampling:** Reduce el n煤mero de muestras de la clase mayoritaria.
* **Oversampling:** Aumenta el n煤mero de muestras de la clase minoritaria, a menudo mediante la replicaci贸n o generaci贸n sint茅tica de datos..
    * Una biblioteca recomendada para esto es `imbalanced-learn`.

![[Pasted image 20250530132705.png]]


* **Entrenamiento en dos etapas (para Deep Learning):**
    * Primero, se entrena el modelo con datos re-muestreados (por ejemplo, haciendo undersampling de las clases mayoritarias hasta balancear el dataset).
    * Luego, se realiza un *fine-tuning* con el dataset original completo.
* **Muestreo din谩mico durante el entrenamiento:**
    * Realiza oversampling de las clases con menor rendimiento.
    * Realiza undersampling de las clases con mejor rendimiento.

#### 3. M茅todos a Nivel de Algoritmo

En lugar de cambiar la distribuci贸n de los datos, se modifica c贸mo el modelo los aprende:
* **Aprendizaje sensible al costo (Cost-sensitive learning):** Se asigna un costo mayor a clasificar mal ciertas clases (ejemplo: un falso negativo de c谩ncer es m谩s costoso que un falso positivo).
* **Loss ponderada por clase:** Se pondera el impacto en la funci贸n de p茅rdida (loss) seg煤n la relaci贸n entre la cantidad de datos por clase.
* **Loss enfocada (Focal Loss):** Se da mayor impacto en la loss si la confianza en la predicci贸n es menor, lo que ayuda a que el modelo se enfoque en ejemplos dif铆ciles o mal clasificados.

##  Sesgo en ML

El **sesgo** es diferente a un dataset no balanceado, aunque pueden estar relacionados.

### Fuentes de Sesgo

* **Sesgo de selecci贸n:** Ocurre cuando se excluyen ciertas categor铆as o se entrena con datos que no representan la diversidad del entorno de producci贸n (ejemplo: entrenar con im谩genes de un cat谩logo propio y no considerar las de socios). A menudo, algunas clases son m谩s f谩ciles de recolectar que otras.
* **Sesgo de medici贸n:** Sucede cuando la calidad o las caracter铆sticas de los datos de entrenamiento difieren de los datos en producci贸n (ejemplo: entrenar con fotos de alta resoluci贸n y usar fotos de menor calidad en producci贸n). Tambi茅n puede ocurrir si el contexto de las im谩genes o datos influye en la etiqueta en lugar de la caracter铆stica principal (ejemplo: zorros siempre con nieve y perros con pasto, llevando al modelo a centrarse en el fondo).
* **Sesgo de confirmaci贸n:** Es m谩s complejo y amplifica los sesgos sociales ya presentes en el dataset.

### Detecci贸n de Sesgo

Para detectar el sesgo, es fundamental **evaluar el modelo sobre "slices" (segmentos) de los datos**, comparando el rendimiento entre diferentes grupos.

