
## 游 Modelos Basados en 츼rboles

Los modelos basados en 치rboles, como los *Gradient Boosted Trees* (ej. XGBoost, LightGBM), son muy populares por su rendimiento y eficiencia.

* **Pros:**
    * Excelente rendimiento en datos tabulares.
    * Relativamente r치pidos de entrenar.
    * No requieren escalar o normalizar los datos.
    * Robustos a *outliers* y a valores faltantes.
    * Permiten conocer la importancia de las *features*.
* **Contras:**
    * Menos adecuados para datos no estructurados como im치genes o texto.
    * Puede ser dif칤cil interpretarlos a nivel global si son muy profundos.
    * Tienden a *overfit* f치cilmente si no se configuran correctamente.

## 游 Redes Neuronales

Las Redes Neuronales (NN) han revolucionado muchas 치reas del ML, especialmente con los avances en Deep Learning.

* **Pros:**
    * Excelente rendimiento en datos no estructurados (im치genes, texto, audio).
    * Capaces de aprender caracter칤sticas complejas y representaciones de datos (embeddings).
    * Potencial para superar el rendimiento humano en ciertas tareas.
* **Contras:**
    * Requieren grandes cantidades de datos.
    * Tiempo de entrenamiento y recursos computacionales (GPUs) elevados.
    * Dif칤cil de interpretar ("cajas negras").
    * Son propensas a *overfitting*.
    * Sensibles a la escala de los datos.

## 游늳 Modelos Lineales

Los modelos lineales (ej. Regresi칩n Lineal, Regresi칩n Log칤stica) son una opci칩n b치sica pero muy potente.

* **Pros:**
    * R치pidos de entrenar y predecir.
    * F치ciles de interpretar.
    * Menos propensos a *overfitting* si el n칰mero de features es limitado.
    * Ideales como *baselines*.
* **Contras:**
    * Rendimiento inferior en problemas con relaciones no lineales.
    * Necesitan *feature engineering* extensivo para capturar no linealidades.
    * Asumen relaciones lineales entre las variables y el *target*.

## 游 Modelos Ensemble (Bagging vs. Boosting)

Los modelos *ensemble* combinan m칰ltiples modelos (t칤picamente 치rboles de decisi칩n) para mejorar el rendimiento y la robustez.

### Bagging (ej. Random Forest)
* **Concepto:** Entrena m칰ltiples modelos independientes en subconjuntos aleatorios de datos (con reemplazo) y promedia sus predicciones.
* **Ventaja:** Reduce la varianza y el *overfitting*. Si los errores de los modelos individuales no est치n correlacionados, el *ensemble* puede ser muy efectivo.
* **Ejemplo:** Random Forest entrena muchos 치rboles de decisi칩n, cada uno con una parte aleatoria de los datos y las *features*, y luego promedia sus resultados.

### Boosting (ej. Gradient Boosting, XGBoost)
* **Concepto:** Entrena modelos secuencialmente, donde cada nuevo modelo corrige los errores del anterior. Se enfoca en los ejemplos que los modelos previos clasificaron mal.
* **Ventaja:** Reduce el sesgo y puede lograr un rendimiento muy alto. Es mejor cuando hay un sesgo de predicciones alto.
* **Ejemplo:** Un modelo inicial hace predicciones, y los errores de estas predicciones son utilizados para entrenar el siguiente modelo, y as칤 sucesivamente.

| Caracter칤stica              | Bagging                                 | Boosting                                     |
| :-------------------------- | :-------------------------------------- | :------------------------------------------- |
| **Paralelizaci칩n**          | S칤, los modelos se entrenan en paralelo | No, los modelos se entrenan secuencialmente  |
| **Sesgo**                   | Tiende a ser m치s alto                   | Tiende a ser m치s bajo                        |
| **Varianza**                | Tiende a ser m치s bajo                   | Tiende a ser m치s alto                        |
| **Overfitting**             | Menos propenso                          | M치s propenso si no se controla bien          |
| **Complejidad**             | M치s simple                              | M치s complejo                                 |
| **Interpretabilidad**       | Media                                   | Baja                                         |
| **Tiempo de entrenamiento** | R치pido                                  | Lento                                        |
| **Resistencia a outliers**  | Alta                                    | Media                                        |
| **Ejemplos**                | Random Forest, Bagging Trees            | Gradient Boosting, XGBoost, LightGBM         |

## 游늺 Modelos de Clasificaci칩n: Probabilidad vs. Clase Directa

Cuando se hace clasificaci칩n, es importante saber si el modelo debe retornar la **probabilidad** de pertenecer a una clase o directamente la **clase predicha**. Esto impacta la **calibraci칩n** del modelo

### Calibraci칩n

Un modelo est치 **calibrado** si sus probabilidades predichas corresponden a las probabilidades reales del evento
* *Ejemplo:* Si un modelo predice un 80% de probabilidad de lluvia, deber칤a llover el 80% de las veces que da esa predicci칩n.
* **Importancia:** Crucial para la toma de decisiones basada en riesgo (ej., en medicina o finanzas), donde la confianza en la predicci칩n es vital.

## 游뚽 Sesgos en la Predicci칩n

Es importante considerar los sesgos en la predicci칩n:
* **Sesgo de cobertura:** Cuando los datos de entrenamiento no representan adecuadamente a la poblaci칩n de inferencia.
* **Sesgo de muestreo:** Si el m칠todo de recolecci칩n de datos favorece ciertas partes de la poblaci칩n.
* **Sesgo de etiqueta:** Errores o inconsistencias en el proceso de etiquetado.
* **Sesgo de features:** Si las *features* no son adecuadas o est치n mal construidas.
* **Sesgo de optimizaci칩n:** Si el modelo optimiza una m칠trica que no se alinea con el objetivo de negocio.

## 游 Interpretabilidad del Modelo

La interpretabilidad es la capacidad de entender c칩mo o por qu칠 un modelo tom칩 una decisi칩n espec칤fica.

### Razones para la Interpretabilidad

* **Confianza:** Generar confianza en los usuarios y desarrolladores.
* **Identificar sesgos:** Detectar si el modelo est치 discriminando.
* **Debugging:** Entender por qu칠 el modelo falla.
* **Cumplimiento regulatorio:** En industrias como finanzas o salud, es a menudo un requisito legal.
* **Mejora del modelo:** Identificar 치reas donde el modelo puede mejorar.
* **Descubrimiento cient칤fico:** Obtener insights de los datos.

### Tipos de Modelos (de m치s interpretable a menos)

* **Lineal/Regresi칩n Log칤stica:** Muy interpretables, se puede ver la contribuci칩n de cada *feature*.
* **츼rboles de decisi칩n:** Razonablemente interpretables; se pueden visualizar las reglas.
* **XGBoost/Random Forest:** Menos interpretables que un solo 치rbol, pero se puede obtener la importancia de las *features*.
* **Redes neuronales:** Generalmente las menos interpretables ("cajas negras").



## 游빔 Baselines y Modelos Simples

Es fundamental comenzar siempre con una **baseline** simple y entender su rendimiento:
* **Baseline:** Un modelo simple o una heur칤stica que sirve como punto de referencia para evaluar modelos m치s complejos.
    * *Ejemplo:* Predecir siempre la clase m치s frecuente en un problema de clasificaci칩n.
* **Importancia:** Un modelo simple a veces puede ser lo suficientemente bueno y evitar complejidades innecesarias. Siempre se debe evaluar si las ganancias de un modelo m치s complejo justifican los costos adicionales (computacionales, de mantenimiento, etc.).
